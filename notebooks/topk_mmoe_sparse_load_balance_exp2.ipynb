{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b71820-c9fe-4235-871f-634550a52f10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\jupyter file\\CMU_3\\distributed ML\\project\n",
      "WARNING:tensorflow:From C:\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd ../\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import ast\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "from utils import set_all_seed, load_exp2_dataset\n",
    "from topk_mmoe import TopkMMoE\n",
    "from trainer_and_evaluator import train_TopkMMoE, eval_TopkMMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca68d7d-d2ae-4f1d-bd9c-b139f48de1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Pearson correlation coefficient: 0.16661069841980908\n",
      "P-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "set_all_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = load_exp2_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9da1d9-c2cc-40f1-a61f-cfa6d3997de2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp2_topk_mmoe_sparse:batch_size=256_N_epochs=50_lr=0.0001_feature_dim=114_expert_dim=32_n_expert=16_n_activated_expert=4_n_task=2_sparse_load_balancing_loss_coef=0.01_olmo_load_balancing_loss_coef=0_router_z_loss_coef=0_gate_dropout=0_tower_dropout=0_expert_dropout=0\n",
      "model/exp2_topk_mmoe_sparse/batch_size=256_N_epochs=50_lr=0.0001_114_32_16_4_2_0.01_0_0_0_0_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myuntaozh\u001b[0m (\u001b[33mzhengyuntao\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\jupyter file\\CMU_3\\distributed ML\\project\\wandb\\run-20241128_014506-1m3hmkyf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zhengyuntao/mmoe/runs/1m3hmkyf' target=\"_blank\">exp2_topk_mmoe_sparse:batch_size=256_N_epochs=50_lr=0.0001_feature_dim=114_expert_dim=32_n_expert=16_n_activated_expert=4_n_task=2_sparse_load_balancing_loss_coef=0.01_olmo_load_balancing_loss_coef=0_router_z_loss_coef=0_gate_dropout=0_tower_dropout=0_expert_dropout=0</a></strong> to <a href='https://wandb.ai/zhengyuntao/mmoe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zhengyuntao/mmoe' target=\"_blank\">https://wandb.ai/zhengyuntao/mmoe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zhengyuntao/mmoe/runs/1m3hmkyf' target=\"_blank\">https://wandb.ai/zhengyuntao/mmoe/runs/1m3hmkyf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/zhengyuntao/mmoe/runs/1m3hmkyf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x22743b6c850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设定各种超参数，wandb日志名，日志存储路径，模型存储路径\n",
    "train_params = {\n",
    "    \"batch_size\": 256,\n",
    "    \"N_epochs\": 50,\n",
    "    \"lr\": 0.0001\n",
    "}\n",
    "\n",
    "# 仅设置dropout\n",
    "model_params={\n",
    "    \"feature_dim\": 114,\n",
    "    \"expert_dim\": 32,\n",
    "    \"n_expert\": 16,\n",
    "    \"n_activated_expert\": 4,\n",
    "    \"n_task\": 2,\n",
    "    \"sparse_load_balancing_loss_coef\": 1e-2, # 仅设置sparse_load_balancing_loss_coef\n",
    "    \"olmo_load_balancing_loss_coef\": 0,\n",
    "    \"router_z_loss_coef\": 0,\n",
    "    \"gate_dropout\": 0,\n",
    "    \"tower_dropout\": 0,\n",
    "    \"expert_dropout\": 0\n",
    "}\n",
    "\n",
    "model_name=\"exp2_topk_mmoe_sparse\"\n",
    "if not os.path.exists(\"model/\"+model_name):\n",
    "    os.makedirs(\"model/\"+model_name) \n",
    "\n",
    "train_params_str = \"_\".join(f\"{key}={value}\" for key, value in train_params.items())\n",
    "model_params_str = \"_\".join(f\"{key}={value}\" for key, value in model_params.items())\n",
    "short_model_params_str = \"_\".join(f\"{value}\" for key, value in model_params.items())\n",
    "\n",
    "wandb_name=model_name+\":\"+train_params_str+\"_\"+model_params_str\n",
    "\n",
    "# 使用short_model_params_str是因为windows支持的最长文件名长度仅为260\n",
    "bestmodel_save_dir=f\"model/\"+model_name+\"/\"+train_params_str+\"_\"+short_model_params_str \n",
    "\n",
    "print(wandb_name)\n",
    "print(bestmodel_save_dir)\n",
    "\n",
    "wandb.init(project=\"mmoe\", name=wandb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af593b44-aa48-4f35-88df-2165577e1242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 45586\n",
      "Number of parameters in SparseMMoE: 43584\n",
      "Number of activated parameters in SparseMMoE: 10896\n"
     ]
    }
   ],
   "source": [
    "mymodel = TopkMMoE(**model_params)\n",
    "\n",
    "nParams = sum([p.nelement() for p in mymodel.parameters()])\n",
    "print('Number of parameters: %d' % nParams)\n",
    "\n",
    "nParams_in_mmoe=0\n",
    "for name,p in mymodel.named_parameters():\n",
    "    if name.startswith(\"sparse_mmoe\"):\n",
    "        nParams_in_mmoe=nParams_in_mmoe+p.nelement()\n",
    "print('Number of parameters in SparseMMoE: %d' % nParams_in_mmoe)\n",
    "# 相比于MMOE增加了w_noises和b_noises\n",
    "print(f'Number of activated parameters in SparseMMoE: {int(nParams_in_mmoe*model_params[\"n_activated_expert\"]/model_params[\"n_expert\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33fc8dbd-93af-4087-b32a-d0132258ec9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using device:cuda\n",
      "Epoch=0,train_loss=0.8102546334266663,val_loss=0.48566851019859314\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=1,train_loss=0.4043387472629547,val_loss=0.3496394455432892\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=2,train_loss=0.3098680377006531,val_loss=0.29183125495910645\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=3,train_loss=0.27303797006607056,val_loss=0.25579461455345154\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=4,train_loss=0.25874996185302734,val_loss=0.24581268429756165\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=5,train_loss=0.24196338653564453,val_loss=0.23312921822071075\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=6,train_loss=0.23464198410511017,val_loss=0.22979699075222015\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=7,train_loss=0.23039406538009644,val_loss=0.22442112863063812\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=8,train_loss=0.21975941956043243,val_loss=0.22745931148529053\n",
      "Epoch=9,train_loss=0.21429182589054108,val_loss=0.22292543947696686\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=10,train_loss=0.21740755438804626,val_loss=0.21493716537952423\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=11,train_loss=0.2140987366437912,val_loss=0.2208300083875656\n",
      "Epoch=12,train_loss=0.21111081540584564,val_loss=0.21431611478328705\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=13,train_loss=0.21094973385334015,val_loss=0.225288987159729\n",
      "Epoch=14,train_loss=0.20672456920146942,val_loss=0.20768870413303375\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=15,train_loss=0.2044968158006668,val_loss=0.20464946329593658\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=16,train_loss=0.2059323638677597,val_loss=0.20697452127933502\n",
      "Epoch=17,train_loss=0.2006336897611618,val_loss=0.20874325931072235\n",
      "Epoch=18,train_loss=0.1955336481332779,val_loss=0.20296764373779297\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=19,train_loss=0.1909078061580658,val_loss=0.19879241287708282\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=20,train_loss=0.19595636427402496,val_loss=0.20610311627388\n",
      "Epoch=21,train_loss=0.22436842322349548,val_loss=0.20545361936092377\n",
      "Epoch=22,train_loss=0.18854063749313354,val_loss=0.19812196493148804\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=23,train_loss=0.18485569953918457,val_loss=0.1967376470565796\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=24,train_loss=0.18556135892868042,val_loss=0.19238874316215515\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=25,train_loss=0.1955915242433548,val_loss=0.1988549679517746\n",
      "Epoch=26,train_loss=0.18418754637241364,val_loss=0.20035117864608765\n",
      "Epoch=27,train_loss=0.1864813268184662,val_loss=0.19551436603069305\n",
      "Epoch=28,train_loss=0.18140561878681183,val_loss=0.20196537673473358\n",
      "Epoch=29,train_loss=0.1782217174768448,val_loss=0.19428741931915283\n",
      "Epoch=30,train_loss=0.18388547003269196,val_loss=0.19126737117767334\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=31,train_loss=0.18041864037513733,val_loss=0.19339407980442047\n",
      "Epoch=32,train_loss=0.186346173286438,val_loss=0.20412634313106537\n",
      "Epoch=33,train_loss=0.18638761341571808,val_loss=0.20296095311641693\n",
      "Epoch=34,train_loss=0.18005381524562836,val_loss=0.19447574019432068\n",
      "Epoch=35,train_loss=0.1801566630601883,val_loss=0.20582769811153412\n",
      "Epoch=36,train_loss=0.1799679547548294,val_loss=0.19276215136051178\n",
      "Epoch=37,train_loss=0.18149377405643463,val_loss=0.20796366035938263\n",
      "Epoch=38,train_loss=0.1749064177274704,val_loss=0.19196854531764984\n",
      "Epoch=39,train_loss=0.1730446219444275,val_loss=0.19061823189258575\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=40,train_loss=0.17613151669502258,val_loss=0.20313511788845062\n",
      "Epoch=41,train_loss=0.17429287731647491,val_loss=0.18989288806915283\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=42,train_loss=0.16906531155109406,val_loss=0.18224366009235382\n",
      "current epoch is the best so far. Saving model...\n",
      "Epoch=43,train_loss=0.16817258298397064,val_loss=0.19523483514785767\n",
      "Epoch=44,train_loss=0.16859152913093567,val_loss=0.1882406324148178\n",
      "Epoch=45,train_loss=0.16583922505378723,val_loss=0.19146433472633362\n",
      "Epoch=46,train_loss=0.1679394245147705,val_loss=0.20153988897800446\n",
      "Epoch=47,train_loss=0.16753888130187988,val_loss=0.19164542853832245\n",
      "Epoch=48,train_loss=0.16515600681304932,val_loss=0.1885608583688736\n",
      "Epoch=49,train_loss=0.16328942775726318,val_loss=0.18569326400756836\n"
     ]
    }
   ],
   "source": [
    "losses, val_losses, adam_batch_loss= train_TopkMMoE(mymodel,\n",
    "                                           train_dataset,\n",
    "                                           val_dataset,\n",
    "                                           bestmodel_save_dir,\n",
    "                                           **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07be8985-798b-47da-aa00-f79836a6ee4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best model based on validation\n",
    "mybestmodel = TopkMMoE(**model_params)\n",
    "mybestmodel.load_state_dict(torch.load(bestmodel_save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89fdb611-85ee-4def-809e-154933380a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9768184556957401\n",
      "AUC: 0.9912384859843681\n"
     ]
    }
   ],
   "source": [
    "auc1, auc2=eval_TopkMMoE(mybestmodel, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56974f0-095e-4ba7-a182-042fc24e7f69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.244 MB of 1.244 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>load_balancing_loss</td><td>█▄▃▄▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>router_z_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>task1_loss</td><td>▆█▃▃▃▃▃▃▃▄▂▃▃▄▃▃▃▂▂▂▂▂▂▁▂▃▄▂▂▂▃▂▃▂▂▂▃▂▃▂</td></tr><tr><td>task2_loss</td><td>█▆▄▂▄▂▂▃▂▁▂▃▂▂▂▂▁▃▁▂▁▂▃▁▂▁▂▄▂▁▂▁▁▂▁▂▂▁▁▂</td></tr><tr><td>task_0/expert_0_weight</td><td>▁▁▅▃▅█▅▆█▆▅▁▅▄▃▅▅▅▄▆█▅▃▃▃▅▅▄▄▄▃▄▄▅▅▃▄▃▄▄</td></tr><tr><td>task_0/expert_10_weight</td><td>█▃▄▃▄▄▆▆▄▅▁▃▄▅▄▆▅▄▅▆▄▇▄▄▅▇▄▄▄▆▃▆▅▃▅▃▆▅▄▄</td></tr><tr><td>task_0/expert_11_weight</td><td>█▂▁▁▃▃▁▄▄▃▄▃▃▃▂▃▂▄▅▃▃▄▃▄▄▃▄▄▃▄▃▄▃▃▂▄▄▄▃▂</td></tr><tr><td>task_0/expert_12_weight</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▂▃▂▃▃▄▃▄▃▃▄▄▃▃▃▄▄▄▃▃▄▄▅</td></tr><tr><td>task_0/expert_13_weight</td><td>▁▁▁▇█▆▆▆▄▇▅▇▄▅▆▅▆▆▄▄▄▇▅▅▅▄▄▄▆▄▅▄▅▇▄▆▆▂▇▃</td></tr><tr><td>task_0/expert_14_weight</td><td>▁▇▆▅▆▄▆▆▅▄▅▆▄█▅▅▅▆▆▃▆▅▅▄▅▅▄▆▇▅▅▆▄▅▄▅▅▄▄▄</td></tr><tr><td>task_0/expert_15_weight</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>task_0/expert_1_weight</td><td>▁▂▅▅▇▄▆▄█▆▇▇█▆▅▅▇▅▃▆▄▆▇▅▅▇▇▄▄▇▆▄▄▆▆▃▅▇▆▇</td></tr><tr><td>task_0/expert_2_weight</td><td>▁▆██▅▆▅▅▇▆▆▆▇▅▇▅▆▃▅▅▅▇▅▅▆▄▆▃▄▆▇▄▅▃▇▅▃█▅▆</td></tr><tr><td>task_0/expert_3_weight</td><td>▁▂▄▄▄▅▄▃▅▃▆▄▄▃█▄▄▃▄▃▃▂▅▄▃▃▄▄▃▂▄▄▃▃▄▃▂▃▂▄</td></tr><tr><td>task_0/expert_4_weight</td><td>▁▄█▇▃▃▄▄▂▅▅█▇▄▄▅▆█▆▄▄▃▁▅▄▅▅▅▃▅▅▅▆▃▆▄▆▆▅▆</td></tr><tr><td>task_0/expert_5_weight</td><td>█▄▂▂▂▂▂▂▁▂▁▃▂▂▂▃▂▂▂▃▂▃▂▂▃▃▂▂▂▂▂▃▂▂▂▃▃▂▃▂</td></tr><tr><td>task_0/expert_6_weight</td><td>▇█▇▆▂▄▄▁▄█▄▄▂▆▂▂▄▅▃▆▄▅▆▆▂▅▄▆▃▆▃▅▃█▃▇▄▅▁▄</td></tr><tr><td>task_0/expert_7_weight</td><td>▁█▅▄▅▄▆▅▁▄█▄▃▅▅▄▄▂▃▅▅▃▃▂▃▃▄▄▅▃▅▄▄▄▃▃▅▂▅▅</td></tr><tr><td>task_0/expert_8_weight</td><td>▂██▆▄▆▆▅▆▅▁▄▇▄▆▅▄▆▄▆▄▂▅▆▅▃▅▄▄▄▄▄▅▅▅▅▄▅▆▅</td></tr><tr><td>task_0/expert_9_weight</td><td>▁▃▄▅▄▅▅▅▄▄█▅▄▄▄▃▅▃▅▃▄▃▃▄▄▄▃▄▅▄▅▃▄▄▄▄▅▄▄▄</td></tr><tr><td>task_1/expert_0_weight</td><td>▄▁▁▁▄█▆▅▅▁▄▆▆▅▅▄▅▁▁▁▁█▄▃▅▁▁▁▁▁▁▁▁▁▄▅▁▁▁▄</td></tr><tr><td>task_1/expert_10_weight</td><td>▅████▆▄▄▆▇▅▇▇▆▆▆▆▄▄▅▁▅▆▆▅▅▆▄▆▆▇▄▆▆▅▅▁▆▅▄</td></tr><tr><td>task_1/expert_11_weight</td><td>▁▁▇█▅▆▄▄▄▃▅▃▄▄▅▅▄▅▅▅▄▄▆▃▄▆▄▄▄▄▃▄▄▄▄▄▄▅▅▄</td></tr><tr><td>task_1/expert_12_weight</td><td>█▅▃▄▃▂▃▃▂▃▃▃▂▂▂▂▃▂▃▂▃▂▂▂▁▃▂▂▃▃▂▂▂▂▂▁▁▃▂▂</td></tr><tr><td>task_1/expert_13_weight</td><td>▁▁▃▆▄▇▄▃▄▆▇▃▆▅▆▆▇▅▄▅▆▅▆▅▆▅▅▅▄▃▄▄▄█▄▅█▅▇▄</td></tr><tr><td>task_1/expert_14_weight</td><td>▂█▅▆▅▃▆▄▅▆▄▄▃▂▄▄▄▆▆▁▄▅▆▅▃▆▅▅▅▆▅▃▇▃▄▃▆▃▅▆</td></tr><tr><td>task_1/expert_15_weight</td><td>▄▅█▃▂▂▂▂▅▃▃▂▁▅▂▄▃▆▃▅▅▃▃▃▁▄▃▄▄▄▆▃▂▃▃▄▅▅▃▄</td></tr><tr><td>task_1/expert_1_weight</td><td>▃▁▄█▅▅█▅▇▃▄▃▆▄▄▄▄▆▇█▆▃▄▄▂▄▆▆▅▃▂▅▄▅▆▅▅▅▁▃</td></tr><tr><td>task_1/expert_2_weight</td><td>▅▅▅▅▅▅▆▅▅▅▆▆▄█▅▆▆▅▆▇▄▅▅▆▇▇▇▆▆▅▇█▁▅▅▅▆▆▅▅</td></tr><tr><td>task_1/expert_3_weight</td><td>▂▁▁▆▆▂▅▆▅▆█▇▆▆▇▆▅▆▆▅▅▄▆▅▅▅▄▆▅▄▄▆▂▅▄▄▄▄▅▅</td></tr><tr><td>task_1/expert_4_weight</td><td>▇█▄▃▃▃▃▃▃▃▄▄▄▄▄▃▃▄▃▄▁▃▄▄▄▄▄▄▃▃▃▄▄▃▄▃▃▃▃▃</td></tr><tr><td>task_1/expert_5_weight</td><td>▁▁▁▁▅▂▃▅▅▇▂▄▅▇▄▄▆▆▄▁▅▅▁▄▇▁▁▁▁▂▄▇█▆▆▅▅▆▅▅</td></tr><tr><td>task_1/expert_6_weight</td><td>▃▆▄▁▃█▃▆▅▆▆▄▄▄▆▆▅▅▅▅▇▇▅▅▄▄▄▄▃▅▆▄▆▅▄▄▅▆▄▄</td></tr><tr><td>task_1/expert_7_weight</td><td>▃▃█▆▅▅▅▇▅▅▂▅▆▆▅▆▆▁▅▇█▅▅▇▂█▆▇▇▇▄▃▆▅▃▅▅▂▇▄</td></tr><tr><td>task_1/expert_8_weight</td><td>▄▃▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▆▁▄▄▇▄▆▆▆▇▆▅▅▇▆▆█▅▆▆</td></tr><tr><td>task_1/expert_9_weight</td><td>▃▃▂▂▄▄▄▃▂▂▂▄▄▂▂▂▁▁▁▂▂▂▃▃█▄▄▄▅▆▅▄▆▃▄▆▅▂▆▅</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>load_balancing_loss</td><td>0.00384</td></tr><tr><td>router_z_loss</td><td>0.0</td></tr><tr><td>task1_loss</td><td>0.06547</td></tr><tr><td>task2_loss</td><td>0.11164</td></tr><tr><td>task_0/expert_0_weight</td><td>0.0681</td></tr><tr><td>task_0/expert_10_weight</td><td>0.081</td></tr><tr><td>task_0/expert_11_weight</td><td>0.08259</td></tr><tr><td>task_0/expert_12_weight</td><td>0.07184</td></tr><tr><td>task_0/expert_13_weight</td><td>0.05998</td></tr><tr><td>task_0/expert_14_weight</td><td>0.06666</td></tr><tr><td>task_0/expert_15_weight</td><td>0.0</td></tr><tr><td>task_0/expert_1_weight</td><td>0.08984</td></tr><tr><td>task_0/expert_2_weight</td><td>0.0613</td></tr><tr><td>task_0/expert_3_weight</td><td>0.0565</td></tr><tr><td>task_0/expert_4_weight</td><td>0.07384</td></tr><tr><td>task_0/expert_5_weight</td><td>0.07399</td></tr><tr><td>task_0/expert_6_weight</td><td>0.07537</td></tr><tr><td>task_0/expert_7_weight</td><td>0.03024</td></tr><tr><td>task_0/expert_8_weight</td><td>0.06206</td></tr><tr><td>task_0/expert_9_weight</td><td>0.04668</td></tr><tr><td>task_1/expert_0_weight</td><td>0.04019</td></tr><tr><td>task_1/expert_10_weight</td><td>0.07302</td></tr><tr><td>task_1/expert_11_weight</td><td>0.0763</td></tr><tr><td>task_1/expert_12_weight</td><td>0.02331</td></tr><tr><td>task_1/expert_13_weight</td><td>0.05021</td></tr><tr><td>task_1/expert_14_weight</td><td>0.05931</td></tr><tr><td>task_1/expert_15_weight</td><td>0.04549</td></tr><tr><td>task_1/expert_1_weight</td><td>0.06437</td></tr><tr><td>task_1/expert_2_weight</td><td>0.06407</td></tr><tr><td>task_1/expert_3_weight</td><td>0.06229</td></tr><tr><td>task_1/expert_4_weight</td><td>0.06396</td></tr><tr><td>task_1/expert_5_weight</td><td>0.07759</td></tr><tr><td>task_1/expert_6_weight</td><td>0.08883</td></tr><tr><td>task_1/expert_7_weight</td><td>0.08069</td></tr><tr><td>task_1/expert_8_weight</td><td>0.07513</td></tr><tr><td>task_1/expert_9_weight</td><td>0.05522</td></tr><tr><td>train_loss</td><td>0.16329</td></tr><tr><td>val_loss</td><td>0.18569</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exp2_topk_mmoe_sparse:batch_size=256_N_epochs=50_lr=0.0001_feature_dim=114_expert_dim=32_n_expert=16_n_activated_expert=4_n_task=2_sparse_load_balancing_loss_coef=0.01_olmo_load_balancing_loss_coef=0_router_z_loss_coef=0_gate_dropout=0_tower_dropout=0_expert_dropout=0</strong> at: <a href='https://wandb.ai/zhengyuntao/mmoe/runs/1m3hmkyf' target=\"_blank\">https://wandb.ai/zhengyuntao/mmoe/runs/1m3hmkyf</a><br/> View project at: <a href='https://wandb.ai/zhengyuntao/mmoe' target=\"_blank\">https://wandb.ai/zhengyuntao/mmoe</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241128_014506-1m3hmkyf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0195f225-b104-4736-ba42-5604730c31c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
